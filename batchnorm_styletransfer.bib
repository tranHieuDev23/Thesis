@misc{radford2015unsupervised,
  abstract    = {In recent years, supervised learning with convolutional networks (CNNs) has
seen huge adoption in computer vision applications. Comparatively, unsupervised
learning with CNNs has received less attention. In this work we hope to help
bridge the gap between the success of CNNs for supervised learning and
unsupervised learning. We introduce a class of CNNs called deep convolutional
generative adversarial networks (DCGANs), that have certain architectural
constraints, and demonstrate that they are a strong candidate for unsupervised
learning. Training on various image datasets, we show convincing evidence that
our deep convolutional adversarial pair learns a hierarchy of representations
from object parts to scenes in both the generator and discriminator.
Additionally, we use the learned features for novel tasks - demonstrating their
applicability as general image representations.},
  added-at    = {2019-11-01T17:00:38.000+0100},
  author      = {Radford, Alec and Metz, Luke and Chintala, Soumith},
  biburl      = {https://www.bibsonomy.org/bibtex/2a114a1bd36bb9b5542f620b0c1d1c050/jil},
  description = {Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},
  interhash   = {ae6fc4b7593a1d0e31aeeff9fef81a36},
  intrahash   = {a114a1bd36bb9b5542f620b0c1d1c050},
  keywords    = {cnn convolution deep generative learning nn},
  note        = {cite arxiv:1511.06434Comment: Under review as a conference paper at ICLR 2016},
  timestamp   = {2019-11-01T17:00:38.000+0100},
  title       = {Unsupervised Representation Learning with Deep Convolutional Generative
  Adversarial Networks},
  url         = {http://arxiv.org/abs/1511.06434},
  year        = 2015
}


